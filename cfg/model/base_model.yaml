# Hyperparameters shared by all architecture variants we test.

name: ??
# Dataset related parameters
augment: False          # Weather to use data-augmentation of the dataset if the system has symmetries.
# Model hyperparameters
activation: ReLU
num_layers: 5                                   # Number MLPs' layers (including input and output layers)
num_hidden_units: 128                           # Number of hidden units in each layer
batch_norm: True
bias: False

# Optimization hyperparameters parameters
lr: 1e-3
batch_size: 1024


